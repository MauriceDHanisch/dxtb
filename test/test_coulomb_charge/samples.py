"""Data for testing Coulomb contribution."""

from typing import Dict
import torch
from xtbml.typing import Molecule, Tensor
from xtbml.utils import symbol2number


class Record(Molecule):
    """Format of reference records containing GFN1-xTB and GFN2-xTB reference values."""

    qat: Tensor
    """Atomic partial charges for this structure."""

    gfn1: Tensor
    """Reference values for GFN1-xTB"""

    gfn2: Tensor
    """Reference values for GFN1-xTB"""


Samples = Dict[str, Record]

mb16_43: Samples = {
    "01": {
        "gfn1": torch.tensor(0.10952019883948200),
        "gfn2": torch.tensor(0.0),
        "numbers": symbol2number(
            [
                "Na",
                "H",
                "O",
                "H",
                "F",
                "H",
                "H",
                "O",
                "N",
                "H",
                "H",
                "Cl",
                "B",
                "B",
                "N",
                "Al",
            ]
        ),
        "positions": torch.tensor(
            [
                -1.85528263484662,
                3.58670515364616,
                -2.41763729306344,
                4.40178023537845,
                0.02338844412653,
                -4.95457749372945,
                -2.98706033463438,
                4.76252065456814,
                1.27043301573532,
                0.79980886075526,
                1.41103455609189,
                -5.04655321620119,
                -4.20647469409936,
                1.84275767548460,
                4.55038084858449,
                -3.54356121843970,
                -3.18835665176557,
                1.46240021785588,
                2.70032160109941,
                1.06818452504054,
                -1.73234650374438,
                3.73114088824361,
                -2.07001543363453,
                2.23160937604731,
                -1.75306819230397,
                0.35951417150421,
                1.05323406177129,
                5.41755788583825,
                -1.57881830078929,
                1.75394002750038,
                -2.23462868255966,
                -2.13856505054269,
                4.10922285746451,
                1.01565866207568,
                -3.21952154552768,
                -3.36050963020778,
                2.42119255723593,
                0.26626435093114,
                -3.91862474360560,
                -3.02526098819107,
                2.53667889095925,
                2.31664984740423,
                -2.00438948664892,
                -2.29235136977220,
                2.19782807357059,
                1.12226554109716,
                -1.36942007032045,
                0.48455055461782,
            ],
        ).reshape((-1, 3)),
        "qat": torch.tensor(
            [
                7.73347900345264e-1,
                1.07626888948184e-1,
                -3.66999593831010e-1,
                4.92833325937897e-2,
                -1.83332156197733e-1,
                2.33302086605469e-1,
                6.61837152062315e-2,
                -5.43944165050002e-1,
                -2.70264356583716e-1,
                2.66618968841682e-1,
                2.62725033202480e-1,
                -7.15315510172571e-2,
                -3.73300777019193e-1,
                3.84585237785621e-2,
                -5.05851088366940e-1,
                5.17677238544189e-1,
            ]
        ),
    },
    "02": {
        "gfn1": torch.tensor(0.10635843572138280),
        "gfn2": torch.tensor(0.0),
        "numbers": symbol2number(
            [
                "H",
                "S",
                "B",
                "O",
                "Mg",
                "H",
                "H",
                "H",
                "Si",
                "H",
                "B",
                "Li",
                "F",
                "H",
                "H",
                "S",
            ]
        ),
        "positions": torch.tensor(
            [
                -1.79537625851198,
                -3.77866422935275,
                -1.07883558363403,
                -2.68278833302782,
                0.38892666265890,
                1.66214865238427,
                0.11484649791305,
                1.48857933226955,
                3.65660396510375,
                -1.07998879593946,
                -0.16259121615748,
                -4.55703065871422,
                0.60302832999383,
                4.08816149622342,
                -0.02589373148029,
                -1.22534089315880,
                -1.79981382478068,
                -3.70773173318592,
                -1.33460982049866,
                -4.24819082475503,
                2.72791902701083,
                -0.16278082578516,
                2.41267994179303,
                5.69030695190570,
                2.87802444057103,
                -0.33120525058830,
                1.88311373530297,
                0.68489327931487,
                0.32790204044961,
                -4.20547693710673,
                -1.20919773588330,
                -2.87253762561437,
                0.94064204223101,
                -3.25572604597922,
                2.21241092990940,
                -2.86715549314771,
                -1.83147468262373,
                5.20527293771933,
                -2.26976270603341,
                4.90885865772880,
                -1.92576561961811,
                2.99069919443735,
                1.26806242248758,
                -2.60409341782411,
                0.55162805282247,
                4.11956976339902,
                1.59892866766766,
                -1.39117477789609,
            ],
        ).reshape((-1, 3)),
        "qat": torch.tensor(
            [
                7.38394711236234e-2,
                -1.68354976558608e-1,
                -3.47642833746823e-1,
                -7.05489267186003e-1,
                7.73548301641266e-1,
                2.30207581365386e-1,
                1.02748501676354e-1,
                9.47818107467040e-2,
                2.44260351729187e-2,
                2.34984927037408e-1,
                -3.17839896393030e-1,
                6.67112994818879e-1,
                -4.78119977010488e-1,
                6.57536027459275e-2,
                1.08259054549882e-1,
                -3.58215329983396e-1,
            ]
        ),
    },
    "SiH4": {
        "gfn1": torch.tensor(5.0778974565885598e-004),
        "gfn2": torch.tensor(0.0),
        "numbers": symbol2number(["Si", "H", "H", "H", "H"]),
        "positions": torch.tensor(
            [
                0.00000000000000,
                -0.00000000000000,
                0.00000000000000,
                1.61768389755830,
                1.61768389755830,
                -1.61768389755830,
                -1.61768389755830,
                -1.61768389755830,
                -1.61768389755830,
                1.61768389755830,
                -1.61768389755830,
                1.61768389755830,
                -1.61768389755830,
                1.61768389755830,
                1.61768389755830,
            ],
        ).reshape((-1, 3)),
        "qat": torch.tensor(
            [
                -8.41282505804719e-2,
                2.10320626451180e-2,
                2.10320626451178e-2,
                2.10320626451179e-2,
                2.10320626451179e-2,
            ]
        ),
    },
}
