{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of carbon atoms in alkane_9_carbons: 8\n",
      "Nb of atoms: 26\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import h5py\n",
    "N_Cs = 8\n",
    "\n",
    "with h5py.File('../dxtb/dxtb-gpu/gpu-cpu_analysis/rdkit/alkanes_data_500.hdf5', 'r') as f:\n",
    "    for mol_name, data in f.items():\n",
    "        if mol_name == f\"alkane_{N_Cs}_carbons\":\n",
    "            atomic_numbers = data['atomic_numbers'][:]\n",
    "            coordinates = data['coordinates'][:]\n",
    "\n",
    "print(f\"Number of carbon atoms in {mol_name}: {N_Cs}\")\n",
    "print(f\"Nb of atoms: {len(atomic_numbers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Device: cuda:0\n",
      "\n",
      "\n",
      "Timings\n",
      "-------\n",
      "\n",
      "\u001b[1mObjective                Time (s)        % Total\u001b[0m\n",
      "------------------------------------------------\n",
      "\u001b[1mClassicals                  0.046           5.09\u001b[0m\n",
      " - Repulsion           \u001b[37m     0.028          61.06\u001b[0m\n",
      " - DispersionD3        \u001b[37m     0.013          27.54\u001b[0m\n",
      " - Halogen             \u001b[37m     0.005          11.11\u001b[0m\n",
      "\u001b[1mIntegrals                   0.332          36.98\u001b[0m\n",
      " - Overlap             \u001b[37m     0.328          99.01\u001b[0m\n",
      " - Core Hamiltonian    \u001b[37m     0.003           0.98\u001b[0m\n",
      "\u001b[1mSCF                         0.299          33.31\u001b[0m\n",
      " - Interaction Cache   \u001b[37m     0.001           0.31\u001b[0m\n",
      " - Potential           \u001b[37m     0.198          66.20\u001b[0m\n",
      " - Fock build          \u001b[37m     0.001           0.46\u001b[0m\n",
      " - Diagonalize         \u001b[37m     0.147          49.12\u001b[0m\n",
      " - Density             \u001b[37m     0.007           2.23\u001b[0m\n",
      " - Charges             \u001b[37m     0.007           2.26\u001b[0m\n",
      "\u001b[1mget_refocc                  0.016           1.74\u001b[0m\n",
      "\u001b[1mget_guess                   0.018           2.05\u001b[0m\n",
      "\u001b[1mChrg init                   0.000           0.00\u001b[0m\n",
      "\u001b[1mguess init scp              0.001           0.09\u001b[0m\n",
      "\u001b[1mscf_pure                    0.257          28.67\u001b[0m\n",
      "\u001b[1mxto.equi                    0.254          28.33\u001b[0m\n",
      "\u001b[1m_Rootfinder                 0.254          28.33\u001b[0m\n",
      "\u001b[1mbroyden1                    0.254          28.32\u001b[0m\n",
      "\u001b[1m1st iter                    0.058           6.51\u001b[0m\n",
      "\u001b[1mM Ops bef eigh              0.060           6.66\u001b[0m\n",
      "\u001b[1mCholesky                    0.008           0.91\u001b[0m\n",
      "\u001b[1mL inv                       0.049           5.43\u001b[0m\n",
      "\u001b[1mMatmul                      0.002           0.23\u001b[0m\n",
      "\u001b[1mcupy_eigh                   0.070           7.83\u001b[0m\n",
      "\u001b[1mM Ops aft eigh              0.002           0.23\u001b[0m\n",
      "\u001b[1m1st norm                    0.012           1.31\u001b[0m\n",
      "\u001b[1mJacobian setup              0.000           0.00\u001b[0m\n",
      "\u001b[1miter_nonlin                 0.195          21.79\u001b[0m\n",
      "\u001b[1mJacobian solve              0.005           0.55\u001b[0m\n",
      "\u001b[1mmv                          0.007           0.82\u001b[0m\n",
      "\u001b[1mdx norm                     0.001           0.08\u001b[0m\n",
      "\u001b[1mJacobian update             0.011           1.19\u001b[0m\n",
      "\u001b[1mrmv                         0.004           0.44\u001b[0m\n",
      "\u001b[1mFin. energy                 0.001           0.10\u001b[0m\n",
      "\u001b[1mForces autograd             0.133          14.85\u001b[0m\n",
      "------------------------------------------------\n",
      "Sum                    \u001b[37m     2.347         261.82\u001b[0m\n",
      "\u001b[1mTotal                       0.896         100.00\u001b[0m\n",
      "\n",
      "Device: cpu\n",
      "\n",
      "\n",
      "Timings\n",
      "-------\n",
      "\n",
      "\u001b[1mObjective                Time (s)        % Total\u001b[0m\n",
      "------------------------------------------------\n",
      "\u001b[1mClassicals                  0.010           1.17\u001b[0m\n",
      " - Halogen             \u001b[37m     0.001          11.86\u001b[0m\n",
      " - Repulsion           \u001b[37m     0.002          19.63\u001b[0m\n",
      " - DispersionD3        \u001b[37m     0.007          68.20\u001b[0m\n",
      "\u001b[1mIntegrals                   0.195          21.90\u001b[0m\n",
      " - Overlap             \u001b[37m     0.189          96.79\u001b[0m\n",
      " - Core Hamiltonian    \u001b[37m     0.006           3.20\u001b[0m\n",
      "\u001b[1mSCF                         0.612          68.81\u001b[0m\n",
      " - Interaction Cache   \u001b[37m     0.001           0.22\u001b[0m\n",
      " - Potential           \u001b[37m     0.579          94.57\u001b[0m\n",
      " - Fock build          \u001b[37m     0.006           0.90\u001b[0m\n",
      " - Diagonalize         \u001b[37m     0.539          88.05\u001b[0m\n",
      " - Density             \u001b[37m     0.010           1.56\u001b[0m\n",
      " - Charges             \u001b[37m     0.008           1.26\u001b[0m\n",
      "\u001b[1mget_refocc                  0.000           0.02\u001b[0m\n",
      "\u001b[1mget_guess                   0.002           0.21\u001b[0m\n",
      "\u001b[1mChrg init                   0.000           0.00\u001b[0m\n",
      "\u001b[1mguess init scp              0.000           0.04\u001b[0m\n",
      "\u001b[1mscf_pure                    0.607          68.24\u001b[0m\n",
      "\u001b[1mxto.equi                    0.595          66.93\u001b[0m\n",
      "\u001b[1m_Rootfinder                 0.595          66.93\u001b[0m\n",
      "\u001b[1mbroyden1                    0.595          66.92\u001b[0m\n",
      "\u001b[1m1st iter                    0.017           1.89\u001b[0m\n",
      "\u001b[1mM Ops bef eigh              0.131          14.72\u001b[0m\n",
      "\u001b[1mCholesky                    0.048           5.43\u001b[0m\n",
      "\u001b[1mL inv                       0.075           8.48\u001b[0m\n",
      "\u001b[1mMatmul                      0.007           0.81\u001b[0m\n",
      "\u001b[1mtorch_eigh                  0.371          41.73\u001b[0m\n",
      "\u001b[1mM Ops aft eigh              0.004           0.48\u001b[0m\n",
      "\u001b[1m1st norm                    0.000           0.00\u001b[0m\n",
      "\u001b[1mJacobian setup              0.000           0.00\u001b[0m\n",
      "\u001b[1miter_nonlin                 0.578          65.03\u001b[0m\n",
      "\u001b[1mJacobian solve              0.004           0.39\u001b[0m\n",
      "\u001b[1mmv                          0.006           0.70\u001b[0m\n",
      "\u001b[1mdx norm                     0.000           0.03\u001b[0m\n",
      "\u001b[1mJacobian update             0.009           1.06\u001b[0m\n",
      "\u001b[1mrmv                         0.005           0.59\u001b[0m\n",
      "\u001b[1mFin. energy                 0.000           0.05\u001b[0m\n",
      "\u001b[1mForces autograd             0.067           7.57\u001b[0m\n",
      "------------------------------------------------\n",
      "Sum                    \u001b[37m     4.537         510.13\u001b[0m\n",
      "\u001b[1mTotal                       0.889         100.00\u001b[0m\n",
      "\n",
      "[Comparison]\n",
      "GPU energy: -3.389333e+00\n",
      "CPU energy: -3.389022e+00\n",
      "Max energy diff: 3.139973e-04\n",
      "Max forces diff: 2.098083e-05\n"
     ]
    }
   ],
   "source": [
    "import dxtb\n",
    "from dxtb._src.typing import DD\n",
    "import torch\n",
    "from ase.build import molecule\n",
    "\n",
    "opts = {\"scf_mode\": \"implicit\", \"batch_mode\": 1, \"int_driver\": \"libcint\"}\n",
    "batch_size = 64\n",
    "results = {}\n",
    "\n",
    "for device in [\"cuda:0\", \"cpu\"]:\n",
    "    print(f\"\\nDevice: {device}\")\n",
    "    dd = {\"dtype\": torch.float32, \"device\": torch.device(device)}\n",
    "    numbers = torch.tensor(atomic_numbers, device=dd[\"device\"], dtype=torch.int32)\n",
    "    positions = torch.tensor(coordinates, device=dd[\"device\"], dtype=dd[\"dtype\"])\n",
    "    numbers = torch.stack([numbers] * batch_size)\n",
    "    positions = torch.stack([positions] * batch_size).requires_grad_()\n",
    "    charges = torch.zeros((batch_size,), device=dd[\"device\"], dtype=dd[\"dtype\"])\n",
    "\n",
    "    calc = dxtb.Calculator(numbers, dxtb.GFN1_XTB, **dd, opts=opts, timer=True)\n",
    "    \n",
    "    dxtb.timer.reset()\n",
    "    e = calc.get_energy(positions, chrg=charges)\n",
    "    dxtb.timer.start(\"Forces autograd\")\n",
    "    forces = torch.autograd.grad(sum(e), positions, retain_graph=True)[0]\n",
    "    dxtb.timer.stop(\"Forces autograd\")\n",
    "    dxtb.timer.print(v=0)\n",
    "\n",
    "    results[device] = {\n",
    "        \"energy\": e.detach().cpu(),\n",
    "        \"forces\": forces.detach().cpu()\n",
    "    }\n",
    "\n",
    "# Compare results\n",
    "energy_diff = (results[\"cuda:0\"][\"energy\"] - results[\"cpu\"][\"energy\"]).abs().max()\n",
    "forces_diff = (results[\"cuda:0\"][\"forces\"] - results[\"cpu\"][\"forces\"]).abs().max()\n",
    "\n",
    "print(f\"\\n[Comparison]\")\n",
    "print(f\"GPU energy: {results['cuda:0']['energy'].mean().item():.6e}\")\n",
    "print(f\"CPU energy: {results['cpu']['energy'].mean().item():.6e}\")\n",
    "print(f\"Max energy diff: {energy_diff.item():.6e}\")\n",
    "print(f\"Max forces diff: {forces_diff.item():.6e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dxtb\n",
    "from dxtb._src.typing import DD\n",
    "import ase.build.molecule as molecule\n",
    "import torch.profiler\n",
    "\n",
    "opts = {\"scf_mode\": \"implicit\", \"batch_mode\": 2, \"int_driver\": \"libcint\"}\n",
    "batch_size = 100\n",
    "\n",
    "for device in [\"cpu\", \"cuda:0\"]:\n",
    "    dd = {\"dtype\": torch.float64, \"device\": torch.device(device)}\n",
    "    numbers = torch.tensor(atomic_numbers, device=dd[\"device\"], dtype=torch.int32)\n",
    "    positions = torch.tensor(coordinates, device=dd[\"device\"], dtype=dd[\"dtype\"])\n",
    "    numbers = torch.stack([numbers] * batch_size)\n",
    "    positions = torch.stack([positions] * batch_size).requires_grad_()\n",
    "    charges = torch.zeros((batch_size,), device=dd[\"device\"], dtype=dd[\"dtype\"])\n",
    "\n",
    "    torch.cuda.synchronize() if \"cuda\" in device else None\n",
    "    dxtb.timer.reset()\n",
    "    calc = dxtb.Calculator(numbers, dxtb.GFN1_XTB, **dd, opts=opts, timer=True)\n",
    "\n",
    "    with torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA\n",
    "        ] if \"cuda\" in device else [torch.profiler.ProfilerActivity.CPU],\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    "    ) as prof:\n",
    "        e = calc.get_energy(positions, chrg=charges)\n",
    "        dxtb.timer.start(\"Forces autograd\")\n",
    "        forces = torch.autograd.grad(sum(e), positions, retain_graph=True)[0]\n",
    "        dxtb.timer.stop(\"Forces autograd\")\n",
    "        torch.cuda.synchronize() if \"cuda\" in device else None\n",
    "\n",
    "    dxtb.timer.print(v=0)\n",
    "    print(f\"\\n--- PyTorch Profiler Summary ({device}) ---\")\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\" if \"cuda\" in device else \"cpu_time_total\", row_limit=20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dxtb\n",
    "from dxtb._src.typing import DD\n",
    "import torch\n",
    "import ase.build.molecule as molecule\n",
    "\n",
    "opts = {\"scf_mode\": \"implicit\", \"batch_mode\": 0}\n",
    "\n",
    "for device in [\"cpu\", \"cuda:0\"]:\n",
    "    dd = {\"dtype\": torch.float64, \"device\": torch.device(device)}\n",
    "    numbers = torch.tensor(atomic_numbers, device= dd[\"device\"], dtype = torch.int64)\n",
    "    positions = torch.tensor(coordinates, device = dd['device'], dtype = torch.float64).requires_grad_()\n",
    "\n",
    "    dxtb.timer.reset()\n",
    "    calc = dxtb.Calculator(numbers, dxtb.GFN1_XTB, **dd, opts=opts)\n",
    "    e = calc.get_energy(positions)\n",
    "    forces = calc.get_forces(positions)\n",
    "    dxtb.timer.print(v=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dxtb\n",
    "from dxtb._src.typing import DD\n",
    "import torch\n",
    "import ase.build.molecule as molecule\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup\n",
    "opts = {\"scf_mode\": \"implicit\", \"batch_mode\": 1}\n",
    "\n",
    "batch_sizes = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "timings = {\"cpu\": [], \"cuda:0\": []}\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for device in [\"cpu\", \"cuda:0\"]:\n",
    "        dd: DD = {\"dtype\": torch.float64, \"device\": torch.device(device)}\n",
    "        numbers = torch.tensor(atomic_numbers, device=dd[\"device\"], dtype=torch.int32)\n",
    "        positions = torch.tensor(coordinates, device=dd[\"device\"], dtype=dd[\"dtype\"])\n",
    "\n",
    "        numbers = torch.stack([numbers] * batch_size)\n",
    "        positions = torch.stack([positions] * batch_size)\n",
    "        charges = torch.zeros((batch_size,), device=dd[\"device\"], dtype=dd[\"dtype\"])\n",
    "\n",
    "        dxtb.timer.reset()\n",
    "        calc = dxtb.Calculator(numbers, dxtb.GFN1_XTB, **dd, opts=opts)\n",
    "        e = calc.get_energy(positions, chrg=charges)\n",
    "        dxtb.timer.print(v=5)\n",
    "        total = dxtb.timer.timers[\"total\"].elapsed_time\n",
    "        timings[device].append(total)\n",
    "        print(f\"[{device}] Batch {batch_size} → {total:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "for device in timings:\n",
    "    actual_times = timings[device]\n",
    "    \n",
    "    # Plot actual timings\n",
    "    plt.plot(batch_sizes, actual_times, label=f\"{device}\", marker='o', linestyle='-')\n",
    "    \n",
    "    # Get anchor time at batch size 2\n",
    "    anchor_batch_size = 4\n",
    "    anchor_idx = batch_sizes.index(anchor_batch_size)\n",
    "    anchor_time = actual_times[anchor_idx]\n",
    "    \n",
    "    # Generate linear scaling line\n",
    "    linear_times = [anchor_time * (b / anchor_batch_size) for b in batch_sizes]\n",
    "    plt.plot(batch_sizes, linear_times, linestyle='--', label=f\"{device} (linear)\", alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Total Time (s)\")\n",
    "plt.title(\"dxtb Total Time vs. Batch Size with Linear Scaling Baseline\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dxtb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
