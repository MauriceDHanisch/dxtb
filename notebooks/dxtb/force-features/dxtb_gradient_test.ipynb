{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import dxtb\n",
    "from dxtb.typing import DD\n",
    "from dxtb.config import ConfigCache\n",
    "from dxtb import OutputHandler\n",
    "\n",
    "dd: DD = {\"dtype\": torch.double, \"device\": torch.device(\"cpu\")}\n",
    "\n",
    "# LiH\n",
    "numbers = torch.tensor([3, 1], device=dd[\"device\"])\n",
    "positions = torch.tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 1.5]], **dd) # ** to use dd as kwargs \n",
    "\n",
    "# numbers = torch.tensor([6, 6, 7, 7, 1, 1, 1, 1, 1, 1, 8, 8,], device=dd[\"device\"])\n",
    "# positions = torch.tensor([\n",
    "#                 [-3.81469488143921, +0.09993441402912, 0.00000000000000],\n",
    "#                 [+3.81469488143921, -0.09993441402912, 0.00000000000000],\n",
    "#                 [-2.66030049324036, -2.15898251533508, 0.00000000000000],\n",
    "#                 [+2.66030049324036, +2.15898251533508, 0.00000000000000],\n",
    "#                 [-0.73178529739380, -2.28237795829773, 0.00000000000000],\n",
    "#                 [-5.89039325714111, -0.02589114569128, 0.00000000000000],\n",
    "#                 [-3.71254944801331, -3.73605775833130, 0.00000000000000],\n",
    "#                 [+3.71254944801331, +3.73605775833130, 0.00000000000000],\n",
    "#                 [+0.73178529739380, +2.28237795829773, 0.00000000000000],\n",
    "#                 [+5.89039325714111, +0.02589114569128, 0.00000000000000],\n",
    "#                 [-2.74426102638245, +2.16115570068359, 0.00000000000000],\n",
    "#                 [+2.74426102638245, -2.16115570068359, 0.00000000000000],\n",
    "#                 ], **dd) # ** to use dd as kwargs\n",
    "\n",
    "pos = positions.clone().requires_grad_(True)\n",
    "\n",
    "# instantiate a calculator\n",
    "cache_config = ConfigCache(enabled=True, coefficients=True, mo_energies=True, density=True)\n",
    "cache_config = ConfigCache(enabled=True, coefficients=True, mo_energies=True, density=True, overlap=True)\n",
    "calc = dxtb.Calculator(numbers, dxtb.GFN1_XTB, CACHE_STORE_DENSITY=True, **dd)\n",
    "calc.opts.cache = cache_config\n",
    "\n",
    "OutputHandler.verbosity = 0\n",
    "\n",
    "def get_jacobian(matrix, pos):\n",
    "    matrix_jac = torch.zeros(matrix.shape + pos.shape, dtype=matrix.dtype)\n",
    "    for i, j in np.ndindex(matrix.shape):\n",
    "        matrix_jac[i, j, :, :] = torch.autograd.grad(matrix[i, j], pos, create_graph=True, retain_graph=True)[0]\n",
    "    return matrix_jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -4.5340e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  4.5340e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  4.1503e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00, -4.1503e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.5322e-01,  0.0000e+00,  0.0000e+00],\n",
      "          [-1.5322e-01,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 7.0888e-04,  0.0000e+00,  0.0000e+00],\n",
      "          [-7.0888e-04,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  1.5322e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00, -1.5322e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  7.0888e-04,  0.0000e+00],\n",
      "          [ 0.0000e+00, -7.0888e-04,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  1.0378e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00, -1.0378e-01]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -5.9302e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00,  5.9302e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00, -4.5340e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  4.5340e-02]],\n",
      "\n",
      "         [[ 1.5322e-01,  0.0000e+00,  0.0000e+00],\n",
      "          [-1.5322e-01,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  1.5322e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00, -1.5322e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  1.0378e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00, -1.0378e-01]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -1.0566e-12],\n",
      "          [ 0.0000e+00,  0.0000e+00,  1.0566e-12]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -5.3862e-22],\n",
      "          [ 0.0000e+00,  0.0000e+00,  5.3862e-22]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  4.1503e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00, -4.1503e-03]],\n",
      "\n",
      "         [[ 7.0888e-04,  0.0000e+00,  0.0000e+00],\n",
      "          [-7.0888e-04,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  7.0888e-04,  0.0000e+00],\n",
      "          [ 0.0000e+00, -7.0888e-04,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -5.9302e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00,  5.9302e-03]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -5.3862e-22],\n",
      "          [ 0.0000e+00,  0.0000e+00,  5.3862e-22]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -2.1009e-13],\n",
      "          [ 0.0000e+00,  0.0000e+00,  2.1009e-13]]]], dtype=torch.float64,\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  \n",
    "\n",
    "energy = calc.get_energy(pos)\n",
    "overlap = calc.integrals.build_overlap(pos)\n",
    "hcore = calc.integrals.build_hcore(pos)\n",
    "density = calc.get_density(pos)\n",
    "coefficients = calc.get_coefficients(pos)\n",
    "energies = torch.diag(calc.get_mo_energies(pos))\n",
    "\n",
    "matrix_grad = get_jacobian(hcore, pos)\n",
    "print(matrix_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Output 0 of the user-provided function is independent of input 0. This is not allowed in strict mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdensity_func\u001b[39m(pos):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m calc\u001b[38;5;241m.\u001b[39mget_density(pos)\n\u001b[0;32m----> 6\u001b[0m density_jacobian \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdensity_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m density_jacobian\n",
      "File \u001b[0;32m~/anaconda3/envs/orbnet_tblite/lib/python3.9/site-packages/torch/autograd/functional.py:702\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[1;32m    699\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of the user-provided function is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    700\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindependent of input \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. This is not allowed in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    701\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i, el_idx))\n\u001b[0;32m--> 702\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    703\u001b[0m             jac_i_el\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mzeros_like(inp_el))\n\u001b[1;32m    705\u001b[0m jacobian \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mtuple\u001b[39m(torch\u001b[38;5;241m.\u001b[39mstack(jac_i_el, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mview(out\u001b[38;5;241m.\u001b[39msize()  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m    706\u001b[0m              \u001b[38;5;241m+\u001b[39m inputs[el_idx]\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;28;01mfor\u001b[39;00m (el_idx, jac_i_el) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(jac_i)), )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Output 0 of the user-provided function is independent of input 0. This is not allowed in strict mode."
     ]
    }
   ],
   "source": [
    "from torch.autograd.functional import jacobian\n",
    "\n",
    "\n",
    "def density_func(pos):\n",
    "    return calc.get_density(pos)\n",
    "density_jacobian = jacobian(density_func, pos, strict=True)\n",
    "\n",
    "density_jacobian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hcore: 100%|██████████| 10/10 [00:00<00:00, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -4.5340e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  4.5340e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  4.1503e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00, -4.1503e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.5322e-01,  0.0000e+00,  0.0000e+00],\n",
      "          [-1.5322e-01,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 7.0888e-04,  0.0000e+00,  0.0000e+00],\n",
      "          [-7.0888e-04,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  1.5322e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00, -1.5322e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  7.0888e-04,  0.0000e+00],\n",
      "          [ 0.0000e+00, -7.0888e-04,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  1.0378e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00, -1.0378e-01]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -5.9302e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00,  5.9302e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00, -4.5340e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  4.5340e-02]],\n",
      "\n",
      "         [[ 1.5322e-01,  0.0000e+00,  0.0000e+00],\n",
      "          [-1.5322e-01,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  1.5322e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00, -1.5322e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  1.0378e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00, -1.0378e-01]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -1.0566e-12],\n",
      "          [ 0.0000e+00,  0.0000e+00,  1.0566e-12]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -5.3862e-22],\n",
      "          [ 0.0000e+00,  0.0000e+00,  5.3862e-22]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  4.1503e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00, -4.1503e-03]],\n",
      "\n",
      "         [[ 7.0888e-04,  0.0000e+00,  0.0000e+00],\n",
      "          [-7.0888e-04,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  7.0888e-04,  0.0000e+00],\n",
      "          [ 0.0000e+00, -7.0888e-04,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -5.9302e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00,  5.9302e-03]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -5.3862e-22],\n",
      "          [ 0.0000e+00,  0.0000e+00,  5.3862e-22]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -2.1009e-13],\n",
      "          [ 0.0000e+00,  0.0000e+00,  2.1009e-13]]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dxtb.integrals.wrappers import overlap, hcore\n",
    "from tqdm import tqdm\n",
    "\n",
    "par = dxtb.GFN1_XTB\n",
    "\n",
    "def get_s(pos):\n",
    "    return calc.integrals.build_overlap(pos)\n",
    "    # return overlap(numbers, pos, par)\n",
    "\n",
    "def get_h(pos):\n",
    "    return hcore(numbers, pos, par)\n",
    "\n",
    "def get_p(pos):\n",
    "    return calc.get_density(pos)\n",
    "\n",
    "def get_e(pos):\n",
    "    return torch.diag(calc.get_mo_energies(pos))\n",
    "\n",
    "def get_c(pos):\n",
    "    return calc.get_coefficients(pos)\n",
    "\n",
    "max_iter = 10\n",
    "\n",
    "# for i in tqdm(range(max_iter), desc=\"overlap libcint\"):\n",
    "#     s_grad = integral.get_gradient(drv_mgr.driver)\n",
    "\n",
    "for i in tqdm(range(max_iter), desc=\"hcore\"):    \n",
    "    jacobian = torch.autograd.functional.jacobian(get_h, pos)\n",
    "\n",
    "# for i in tqdm(range(max_iter), desc=\"overlap\"):    \n",
    "#     jacobian = torch.autograd.functional.jacobian(get_s, pos, vectorize=False)\n",
    "\n",
    "# for i in tqdm(range(max_iter), desc=\"density\"):\n",
    "#     jacobian = torch.autograd.functional.jacobian(get_p, pos, vectorize=False)\n",
    "\n",
    "# for i in tqdm(range(max_iter), desc=\"mo energies (diag)\"):\n",
    "#     jacobian = torch.autograd.functional.jacobian(get_e, pos, vectorize=False)\n",
    "\n",
    "# for i in tqdm(range(max_iter), desc=\"coefficients\"):\n",
    "#     jacobian = torch.autograd.functional.jacobian(get_c, pos, vectorize=False)\n",
    "\n",
    "\n",
    "print(jacobian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dxtb.integrals.wrappers import overlap, hcore\n",
    "from dxtb._src.xtb.gfn1 import GFN1Hamiltonian\n",
    "from dxtb import IndexHelper\n",
    "\n",
    "# ovlp = overlap(numbers, pos, dxtb.GFN1_XTB) # independenMagnum duck. n the spin (uhf)\n",
    "\n",
    "par = dxtb.GFN1_XTB\n",
    "ihelp = IndexHelper.from_numbers(numbers, par)\n",
    "\n",
    "# h0 = GFN1Hamiltonian(numbers=numbers, positions=pos, par=par, ihelp=ihelp, **dd)\n",
    "\n",
    "# h = h0.build(pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.9577e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.4528e-02,\n",
      "         -1.7739e-02],\n",
      "        [ 0.0000e+00,  2.3873e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  2.3873e-01,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3873e-01,  5.0428e-02,\n",
      "          4.3236e-04],\n",
      "        [ 4.4528e-02,  0.0000e+00,  0.0000e+00,  5.0428e-02,  7.9577e-02,\n",
      "          6.7673e-11],\n",
      "        [-1.7739e-02,  0.0000e+00,  0.0000e+00,  4.3236e-04,  6.7673e-11,\n",
      "          7.9577e-02]], dtype=torch.float64)\n",
      "s shape: torch.Size([6, 6])\n",
      "s_grad shape: torch.Size([6, 6, 3])\n",
      "tensor([[[-0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0316, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.0316, -0.0000],\n",
      "         [-0.0000, -0.0000,  0.0316],\n",
      "         [-0.0000, -0.0000,  0.0056],\n",
      "         [-0.0000, -0.0000, -0.0007]],\n",
      "\n",
      "        [[-0.0316, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000,  0.0000],\n",
      "         [-0.0336,  0.0000,  0.0000],\n",
      "         [-0.0003, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0316, -0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0000],\n",
      "         [ 0.0000, -0.0336,  0.0000],\n",
      "         [-0.0000, -0.0003, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.0316],\n",
      "         [ 0.0000,  0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0217],\n",
      "         [-0.0000, -0.0000,  0.0024]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.0056],\n",
      "         [ 0.0336,  0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0336, -0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0217],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0000,  0.0007],\n",
      "         [ 0.0003, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.0003, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.0024],\n",
      "         [-0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from dxtb.integrals import DriverManager\n",
    "from dxtb.integrals.factories import new_overlap\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dd: DD = {\"dtype\": torch.double, \"device\": torch.device(\"cpu\")}\n",
    "ihelp = IndexHelper.from_numbers(numbers, par)\n",
    "driver_name = 0 # libcint\n",
    "drv_mgr = DriverManager(driver_name, **dd)\n",
    "drv_mgr.create_driver(numbers, par, ihelp)\n",
    "drv_mgr.driver.setup(positions)\n",
    "\n",
    "integral = new_overlap(drv_mgr.driver_type, **dd)\n",
    "s = integral.build(drv_mgr.driver)\n",
    "\n",
    "print(integral.matrix)\n",
    "\n",
    "s_grad = integral.get_gradient(drv_mgr.driver)\n",
    "\n",
    "print(f\"s shape: {s.shape}\")\n",
    "print(f\"s_grad shape: {s_grad.shape}\")\n",
    "print(integral.gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_full_jacobian(overlap_integral, driver):\n",
    "    \"\"\"\n",
    "    Computes the Jacobian of the overlap integral matrix with respect to atomic positions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    overlap_integral : OverlapLibcint\n",
    "        An instance of the OverlapLibcint class with computed overlap integral.\n",
    "    driver : IntDriverLibcint\n",
    "        The integral driver for the calculation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    jacobian : Tensor\n",
    "        Jacobian of the overlap integral with respect to atomic positions.\n",
    "        Shape: (nao, nao, nat, 3)\n",
    "    \"\"\"\n",
    "    # Compute the gradient of the overlap integral matrix\n",
    "    # Shape: (nao, nao, 3)\n",
    "    overlap_gradient = overlap_integral.get_gradient(driver)\n",
    "\n",
    "    # Obtain mapping from basis functions to atoms\n",
    "    # Shape: (nao,)\n",
    "    ao_to_atom = driver.drv.ao_to_atom()\n",
    "\n",
    "    nao = overlap_gradient.shape[0]  # Number of atomic orbitals\n",
    "    nat = numbers.shape[0]  # Number of atoms\n",
    "\n",
    "    # Initialize the Jacobian tensor\n",
    "    jacobian = torch.zeros((nao, nao, nat, 3), dtype=overlap_gradient.dtype, device=overlap_gradient.device)\n",
    "\n",
    "    # Vectorized implementation to assign gradients to the appropriate atoms\n",
    "    # Create indices for basis functions\n",
    "    indices = torch.arange(nao, device=overlap_gradient.device)\n",
    "\n",
    "    # Create meshgrid of indices\n",
    "    idx_i, idx_j = torch.meshgrid(indices, indices, indexing='ij')\n",
    "\n",
    "    # Map basis functions to atoms\n",
    "    atom_idx_i = ao_to_atom[idx_i]  # Shape: (nao, nao)\n",
    "    atom_idx_j = ao_to_atom[idx_j]  # Shape: (nao, nao)\n",
    "\n",
    "    # Expand gradient to match atoms\n",
    "    grad_expanded = overlap_gradient.unsqueeze(2).expand(-1, -1, 2, 3)  # Shape: (nao, nao, 2, 3)\n",
    "\n",
    "    # Stack atom indices\n",
    "    atom_indices = torch.stack((atom_idx_i, atom_idx_j), dim=2)  # Shape: (nao, nao, 2)\n",
    "\n",
    "    # Flatten tensors for indexing\n",
    "    flat_i = idx_i.flatten()\n",
    "    flat_j = idx_j.flatten()\n",
    "    flat_atoms = atom_indices.reshape(-1, 2)   # Shape: (nao*nao, 2)\n",
    "    flat_grads = grad_expanded.reshape(-1, 2, 3)  # Shape: (nao*nao, 2, 3)\n",
    "\n",
    "    # Accumulate gradients per atom\n",
    "    for k in range(2):\n",
    "        atom_k = flat_atoms[:, k]\n",
    "        grad_k = flat_grads[:, k, :]\n",
    "        jacobian[flat_i, flat_j, atom_k, :] += grad_k\n",
    "\n",
    "    return jacobian  # Shape: (nao, nao, nat, 3)\n",
    "\n",
    "\n",
    "jacobian_lbcint = compute_full_jacobian(integral, drv_mgr.driver)\n",
    "\n",
    "print(jacobian.shape)\n",
    "\n",
    "def get_s(pos):\n",
    "    return overlap(numbers, pos, par)\n",
    "\n",
    "\n",
    "jacobian_autograd = torch.autograd.functional.jacobian(get_s, pos)\n",
    "\n",
    "\n",
    "print(f\"sum of abs diff: {torch.sum(torch.abs(jacobian_lbcint - jacobian_autograd))}\")\n",
    "\n",
    "print(jacobian_lbcint)\n",
    "print(jacobian_autograd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orbnet_tblite_libpath",
   "language": "python",
   "name": "orbnet_tblite_libpath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
