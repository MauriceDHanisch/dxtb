{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy: tensor([ 0.0111, -4.8440], dtype=torch.float64, grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Running a simple batched calculation.\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "import dxtb\n",
    "from dxtb.typing import DD\n",
    "\n",
    "dd: DD = {\"device\": torch.device(\"cpu\"), \"dtype\": torch.double}\n",
    "\n",
    "\n",
    "numbers = torch.tensor(\n",
    "    [\n",
    "        [3, 1, 0],\n",
    "        [8, 1, 1],\n",
    "    ],\n",
    "    device=dd[\"device\"],\n",
    ")\n",
    "positions = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [0.0, 0.0, 0.0],\n",
    "            [0.0, 0.0, 1.0],\n",
    "            [0.0, 0.0, 0.0],\n",
    "        ],\n",
    "        [\n",
    "            [0.0, 0.0, 0.0],\n",
    "            [0.0, 0.0, 1.0],\n",
    "            [0.0, 0.0, 2.0],\n",
    "        ],\n",
    "    ],\n",
    "    **dd\n",
    ").requires_grad_(True)\n",
    "charge = torch.tensor([0, 0], **dd)\n",
    "\n",
    "\n",
    "# no conformers -> batched mode 1\n",
    "opts = {\"verbosity\": 0, \"batch_mode\": 1}\n",
    "\n",
    "calc = dxtb.Calculator(numbers, dxtb.GFN1_XTB, opts=opts, **dd)\n",
    "energy = calc.get_energy(positions, chrg=charge)\n",
    "# forces = calc.get_forces(positions, chrg=charge) # Does not work for batched calculations\n",
    "\n",
    "print(f\"energy: {energy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat[p, p]:\n",
      "[9 1 5]\n",
      "mat[p, :][:, p]:\n",
      "[[9 7 8]\n",
      " [3 1 2]\n",
      " [6 4 5]]\n",
      "mat[np.ix_(p, p)]:\n",
      "[[9 7 8]\n",
      " [3 1 2]\n",
      " [6 4 5]]\n",
      "batch_matrices[:, np.ix_(p, p)[0], np.ix_(p, p)[1]]:\n",
      "[[[9 7 8]\n",
      "  [3 1 2]\n",
      "  [6 4 5]]\n",
      "\n",
      " [[1 3 2]\n",
      "  [7 9 8]\n",
      "  [4 6 5]]]\n",
      "batch_matrices[:, p, :][:, :, p]:\n",
      "[[[9 7 8]\n",
      "  [3 1 2]\n",
      "  [6 4 5]]\n",
      "\n",
      " [[1 3 2]\n",
      "  [7 9 8]\n",
      "  [4 6 5]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example matrix\n",
    "array = np.array([[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]])\n",
    "\n",
    "batch_matrices = np.array([[[1, 2, 3],\n",
    "                            [4, 5, 6],\n",
    "                            [7, 8, 9]],\n",
    "                           [[9, 8, 7],\n",
    "                            [6, 5, 4],\n",
    "                            [3, 2, 1]]])\n",
    "\n",
    "# Example permutation\n",
    "p = [2, 0, 1]\n",
    "\n",
    "# mat[p, p] gives only diagonal elements (permuted)\n",
    "print(\"mat[p, p]:\")\n",
    "print(array[p, p])  # Output: [9 1 5]\n",
    "\n",
    "# mat[p, :][:, p] gives the fully permuted matrix\n",
    "print(\"mat[p, :][:, p]:\")\n",
    "print(array[p, :][:, p])  # Output: full permuted matrix\n",
    "\n",
    "print(\"mat[np.ix_(p, p)]:\")\n",
    "print(array[np.ix_(p, p)])  # Output: full permuted matrix\n",
    "\n",
    "print(\"batch_matrices[:, np.ix_(p, p)[0], np.ix_(p, p)[1]]:\")\n",
    "print(batch_matrices[:, np.ix_(p, p)[0], np.ix_(p, p)[1]])  # Output: full permuted batched matrices\n",
    "\n",
    "print(\"batch_matrices[:, p, :][:, :, p]:\")\n",
    "print(batch_matrices[:, p, :][:, :, p])  # Output: full permuted batched matrices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrices:\n",
      "[[[1 2 3]\n",
      "  [4 5 6]\n",
      "  [7 8 9]]\n",
      "\n",
      " [[9 8 7]\n",
      "  [6 5 4]\n",
      "  [3 2 1]]]\n",
      "\n",
      "Permuted Matrices (Loop Method):\n",
      "[[[9 7 8]\n",
      "  [3 1 2]\n",
      "  [6 4 5]]\n",
      "\n",
      " [[5 4 6]\n",
      "  [2 1 3]\n",
      "  [8 7 9]]]\n",
      "\n",
      "Permuted Matrices (Vectorized Method):\n",
      "[[[9 7 8]\n",
      "  [3 1 2]\n",
      "  [6 4 5]]\n",
      "\n",
      " [[5 4 6]\n",
      "  [2 1 3]\n",
      "  [8 7 9]]]\n",
      "\n",
      "Time taken (Loop method): 0.000274 seconds\n",
      "Time taken (Vectorized method): 0.000202 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Example data\n",
    "n_batch = 2\n",
    "nao = 3\n",
    "\n",
    "# Batched matrices (n_batch, nao, nao)\n",
    "batch_matrices = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]],   # First matrix\n",
    "                           [[9, 8, 7], [6, 5, 4], [3, 2, 1]]])  # Second matrix\n",
    "\n",
    "# Batched permutation maps (n_batch, nao)\n",
    "perm_maps = np.array([[2, 0, 1],  # Perm for first matrix\n",
    "                      [1, 2, 0]]) # Perm for second matrix\n",
    "\n",
    "# ----------------------\n",
    "# Loop method\n",
    "# ----------------------\n",
    "start_loop = time.time()\n",
    "\n",
    "# Initialize the permuted result array\n",
    "permuted_matrices_loop = np.empty_like(batch_matrices)\n",
    "\n",
    "# Apply the permutation for each matrix in the batch\n",
    "for i in range(n_batch):\n",
    "    permuted_matrices_loop[i] = batch_matrices[i][np.ix_(perm_maps[i], perm_maps[i])]\n",
    "\n",
    "end_loop = time.time()\n",
    "\n",
    "# ----------------------\n",
    "# Vectorized method\n",
    "# ----------------------\n",
    "start_vectorized = time.time()\n",
    "\n",
    "# Permute the rows first\n",
    "permuted_rows = np.take_along_axis(batch_matrices, perm_maps[:, :, None], axis=1)\n",
    "\n",
    "# Permute the columns on the row-permuted result\n",
    "permuted_matrices_vectorized = np.take_along_axis(permuted_rows, perm_maps[:, None, :], axis=2)\n",
    "\n",
    "end_vectorized = time.time()\n",
    "\n",
    "# ----------------------\n",
    "# Results\n",
    "# ----------------------\n",
    "print(\"Original Matrices:\")\n",
    "print(batch_matrices)\n",
    "print(\"\\nPermuted Matrices (Loop Method):\")\n",
    "print(permuted_matrices_loop)\n",
    "print(\"\\nPermuted Matrices (Vectorized Method):\")\n",
    "print(permuted_matrices_vectorized)\n",
    "\n",
    "# Time comparison\n",
    "print(\"\\nTime taken (Loop method): {:.6f} seconds\".format(end_loop - start_loop))\n",
    "print(\"Time taken (Vectorized method): {:.6f} seconds\".format(end_vectorized - start_vectorized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import torch\n",
    "\n",
    "from tblite.interface import Calculator\n",
    "import dxtb\n",
    "from dxtb import OutputHandler\n",
    "from dxtb.config import ConfigCache\n",
    "from dxtb.typing import DD\n",
    "\n",
    "possible_elements = [1, 6, 7, 8, 9]\n",
    "\n",
    "\n",
    "def _get_permutation_map_closedshell_convention(element_numbers_batch, calculator=\"tblite\"):\n",
    "    \"\"\"\n",
    "    Create permutation maps to reorder orbital matrices from calculator conventions\n",
    "    to OrbNet-Equi's convention.\n",
    "\n",
    "    Parameters:\n",
    "    - element_numbers_batch: List or array of atomic numbers for each molecule in the batch.\n",
    "    - calculator: str, either \"tblite\" or \"dxtb\".\n",
    "\n",
    "    Returns:\n",
    "    - List of numpy arrays containing permutation indices for each molecule.\n",
    "    \"\"\"\n",
    "    perm_maps = []\n",
    "    for element_numbers in element_numbers_batch:\n",
    "        perm_map = []\n",
    "        idx = 0\n",
    "        for el in element_numbers:\n",
    "            if el == 1:\n",
    "                perm_map.extend([idx, idx + 1])\n",
    "                idx += 2\n",
    "            else:\n",
    "                if calculator == \"tblite\":\n",
    "                    # [s, px, py, pz] -> [s, pz, py, px]\n",
    "                    perm_map.extend([idx, idx + 3, idx + 2, idx + 1])\n",
    "                elif calculator == \"dxtb\":\n",
    "                    # [s, pz, px, py] -> [s, pz, py, px]\n",
    "                    perm_map.extend([idx, idx + 1, idx + 3, idx + 2])\n",
    "                idx += 4\n",
    "        perm_maps.append(perm_map)\n",
    "    return np.array(perm_maps, dtype=np.int64)\n",
    "\n",
    "\n",
    "def apply_perm_map(array, perm_maps, pos):\n",
    "    \"\"\"\n",
    "    Apply a permutation map to a matrix or a batch of matrices.\n",
    "\n",
    "    Parameters:\n",
    "    - array: np.ndarray, shape (n, n), (batch_size, n, n), (batch_size, n, n, nat, 3).\n",
    "    - perm_maps: List of np.ndarray, permutation indices for each element in the batch.\n",
    "    - pos: np.ndarray, atomic positions (currently unused but could be used for future extensions).\n",
    "\n",
    "    Returns:\n",
    "    - Permuted array or batch of permuted array.\n",
    "    \"\"\"\n",
    "    if len(perm_maps) == 1:  # Non-batched case\n",
    "        p = perm_maps[0]\n",
    "        if array.ndim == 2:  # Features (nao, nao)\n",
    "            return array[p, :][:, p]\n",
    "        elif array.ndim == 3 and array.shape[0] == 1:  # Non-batched with batch dimension (1, nao, nao)\n",
    "            return array[:, p, :][:, :, p]\n",
    "        elif array.ndim == 4:  # Gradients (nao, nao, nat, 3)\n",
    "            return array[p, :, :, :][:, p, :, :]\n",
    "        elif array.ndim == 5 and array.shape[0] == 1:  # Gradients with batch dimension (1, nao, nao, nat, 3)\n",
    "            return array[:, p, :, :, :][:, :, p, :, :]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported array shape {array.shape}.\")\n",
    "    else:  # Batched case with multiple permutation maps (same length)\n",
    "        if array.ndim == 3:  # Features (batch_size, nao, nao)\n",
    "            permuted_rows = np.take_along_axis(array, perm_maps[:, :, None], axis=1)\n",
    "            return np.take_along_axis(permuted_rows, perm_maps[:, None, :], axis=2)\n",
    "        if array.ndim == 5:  # Gradients (batch_size, nao, nao, nat, 3)\n",
    "            permuted_rows = np.take_along_axis(array, perm_maps[:, :, None, None, None], axis=1)\n",
    "            return np.take_along_axis(permuted_rows, perm_maps[:, None, :, None, None], axis=2)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported array shape {array.shape}.\")\n",
    "  \n",
    "\n",
    "def generate_xtb_matrices_fpsh_new(\n",
    "        calculator=\"tblite\",\n",
    "        element_numbers=None,\n",
    "        coordinates=None,\n",
    "        spin_pol=False,\n",
    "        cutoff=None,\n",
    "        *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate Fock (F), density (P), overlap (S), and Hamiltonian (H) matrices\n",
    "    using either the 'tblite' or 'dxtb' calculator.\n",
    "\n",
    "    Supports batch processing with the 'dxtb' calculator.\n",
    "\n",
    "    Parameters:\n",
    "    - calculator: str, either \"tblite\" or \"dxtb\" (default: \"tblite\").\n",
    "    - element_numbers: list or np.ndarray, atomic numbers.\n",
    "        Shape: (n_atoms,) for single, (batch_size, n_atoms) for batch.\n",
    "    - coordinates: list or np.ndarray, atomic coordinates in bohr.\n",
    "        Shape: (n_atoms, 3) for single, (batch_size, n_atoms, 3) for batch.\n",
    "    - spin_pol: bool, whether to perform spin-polarized calculations (default: False).\n",
    "    - cutoff: float, threshold below which matrix elements are set to zero (default: None).\n",
    "    - *args, **kwargs: Additional arguments passed to the calculators.\n",
    "\n",
    "    Returns:\n",
    "    - res_dict: dict containing matrices and optionally energy and forces.\n",
    "        If spin_pol=True:\n",
    "            {\"F_a\", \"F_b\", \"P_a\", \"P_b\", \"S\", \"H\", ...}\n",
    "        Else:\n",
    "            {\"F\", \"P\", \"S\", \"H\", ...}\n",
    "    \"\"\"\n",
    "    element_numbers = np.asarray(element_numbers)\n",
    "    coordinates = np.asarray(coordinates)\n",
    "    batched = element_numbers.ndim == 2 and coordinates.ndim == 3\n",
    "\n",
    "    if batched and calculator != \"dxtb\":\n",
    "        raise NotImplementedError(\"Batch processing is only supported with 'dxtb' calculator.\")\n",
    "\n",
    "    if calculator == \"tblite\":\n",
    "        res_dict = generate_xtb_matrices_tblite(\n",
    "            element_numbers=element_numbers,\n",
    "            coordinates=coordinates,\n",
    "            spin_pol=spin_pol,\n",
    "            **kwargs\n",
    "        )\n",
    "    elif calculator == \"dxtb\":\n",
    "        batch_mode = 1 if batched else 0\n",
    "        res_dict = generate_xtb_matrices_dxtb(\n",
    "            element_numbers=element_numbers,\n",
    "            coordinates=coordinates,\n",
    "            spin_pol=spin_pol,\n",
    "            batch_mode=batch_mode,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    # Generate permutation maps\n",
    "    perm_maps = _get_permutation_map_closedshell_convention(\n",
    "        element_numbers_batch=element_numbers if batched else [element_numbers],\n",
    "        calculator=calculator\n",
    "    )\n",
    "\n",
    "    # Apply permutation maps and apply cutoff\n",
    "    for key, mat in res_dict.items():\n",
    "        if cutoff is not None and key not in [\"energy\", \"force\"]:\n",
    "            mat = np.where(np.abs(mat) <= cutoff, 0, mat)\n",
    "        if key not in [\"energy\", \"force\"]:\n",
    "            res_dict[key] = apply_perm_map(\n",
    "                array=mat,\n",
    "                perm_maps=perm_maps,\n",
    "                pos=coordinates\n",
    "            )\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "def generate_xtb_matrices_tblite(\n",
    "        element_numbers,\n",
    "        coordinates,\n",
    "        option=\"GFN1-xTB\",\n",
    "        charge=None,\n",
    "        uhf=None,\n",
    "        spin_pol=False,\n",
    "        get_energy=False,\n",
    "        get_forces=False,\n",
    "        verbosity=False,\n",
    "        **kwargs):\n",
    "    \"\"\"\n",
    "    Generate xTB matrices using the 'tblite' calculator.\n",
    "\n",
    "    Parameters:\n",
    "    - element_numbers: list or np.ndarray, atomic numbers.\n",
    "    - coordinates: list or np.ndarray, atomic coordinates in bohr.\n",
    "    - option: str, xTB method to use (default: \"GFN1-xTB\").\n",
    "    - charge: int, molecular charge (default: None).\n",
    "    - uhf: int, unrestricted Hartree-Fock value (default: None).\n",
    "    - spin_pol: bool, whether to perform spin-polarized calculations (default: False).\n",
    "    - get_energy: bool, whether to compute the total energy (default: False).\n",
    "    - get_forces: bool, whether to compute forces (default: False).\n",
    "    - verbosity: bool, whether to enable verbosity (default: False).\n",
    "    - **kwargs: Additional arguments passed to the tblite calculator.\n",
    "\n",
    "    Returns:\n",
    "    - res_dict: dict containing matrices and optionally energy and forces.\n",
    "        If spin_pol=True:\n",
    "            {\"F_a\", \"F_b\", \"P_a\", \"P_b\", \"S\", \"H\", \"energy\", \"force\"}\n",
    "        Else:\n",
    "            {\"F\", \"P\", \"S\", \"H\", \"energy\", \"force\"}\n",
    "    \"\"\"\n",
    "    calc = Calculator(\n",
    "        method=option,\n",
    "        numbers=element_numbers,\n",
    "        positions=coordinates,\n",
    "        charge=charge,\n",
    "        uhf=uhf,\n",
    "        **kwargs\n",
    "    )\n",
    "    if spin_pol:\n",
    "        calc.add(\"spin-polarization\", 1.0)\n",
    "    calc.set(\"verbosity\", int(verbosity))\n",
    "    calc.set(\"save-integrals\", 1)\n",
    "    res = calc.singlepoint()\n",
    "\n",
    "    S = res.get(\"overlap-matrix\")  # (nao, nao)\n",
    "    H = res.get(\"hamiltonian-matrix\")  # (nao, nao)\n",
    "    P = res.get(\"density-matrix\")  # (nao, nao) or (2, nao, nao)\n",
    "    E = res.get(\"orbital-energies\")  # (nao) or (2, nao)\n",
    "    C = res.get(\"orbital-coefficients\")  # (nao, nao) or (2, nao, nao)\n",
    "\n",
    "    if spin_pol:\n",
    "        F_a = S @ C[0] @ np.diag(E[0]) @ LA.inv(C[0])\n",
    "        F_b = S @ C[1] @ np.diag(E[1]) @ LA.inv(C[1])\n",
    "        res_dict = {\"F_a\": F_a, \"F_b\": F_b, \"P_a\": P[0], \"P_b\": P[1], \"S\": S, \"H\": H}\n",
    "    else:\n",
    "        F = S @ C @ np.diag(E) @ LA.inv(C)\n",
    "        res_dict = {\"F\": F, \"P\": P, \"S\": S, \"H\": H}\n",
    "\n",
    "    if get_energy:\n",
    "        res_dict[\"energy\"] = res.get(\"energy\")\n",
    "    if get_forces:\n",
    "        res_dict[\"force\"] = res.get(\"gradient\")\n",
    "\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "def generate_xtb_matrices_dxtb(\n",
    "        element_numbers,\n",
    "        coordinates,\n",
    "        option=\"GFN1-xTB\",\n",
    "        charge=0,\n",
    "        spin=0,\n",
    "        spin_pol=False,\n",
    "        batch_mode=0,\n",
    "        get_energy=False,\n",
    "        get_forces=False,\n",
    "        get_analytical_gradients=False,\n",
    "        verbosity=False,\n",
    "        **kwargs):\n",
    "    \"\"\"\n",
    "    Generate xTB matrices using the 'dxtb' calculator.\n",
    "\n",
    "    Parameters:\n",
    "    - element_numbers: list or np.ndarray, atomic numbers.\n",
    "        Shape: (n_atoms,) for single, (batch_size, n_atoms) for batch.\n",
    "    - coordinates: list or np.ndarray, atomic coordinates in bohr.\n",
    "        Shape: (n_atoms, 3) for single, (batch_size, n_atoms, 3) for batch.\n",
    "    - option: str, xTB method to use (default: \"GFN1-xTB\").\n",
    "    - charge: int or list, molecular charge(s) (default: 0).\n",
    "    - spin: int or list, number of unpaired electrons (default: 0).\n",
    "    - spin_pol: bool, whether to perform spin-polarized calculations (not supported).\n",
    "    - batch_mode: int, 1 for batched, 0 for single (default: 0).\n",
    "    - get_energy: bool, whether to compute the total energy (default: False).\n",
    "    - get_forces: bool, whether to compute forces (default: False).\n",
    "    - verbosity: bool, whether to enable verbosity (default: False).\n",
    "    - **kwargs: Additional arguments passed to the dxtb calculator.\n",
    "\n",
    "    Returns:\n",
    "    - res_dict: dict containing matrices and optionally energy and forces.\n",
    "        If spin_pol=True (not supported):\n",
    "            {\"F_a\", \"F_b\", \"P_a\", \"P_b\", \"S\", \"H\", \"energy\", \"force\", ...}\n",
    "        Else:\n",
    "            {\"F\", \"P\", \"S\", \"H\", \"energy\", \"force\", ...}\n",
    "    \"\"\"\n",
    "    assert not spin_pol, \"Spin-polarized calculations are not supported for dxtb.\"\n",
    "    par = getattr(dxtb, option.replace('-x', '_X'))\n",
    "    dd: DD = {\"dtype\": torch.double, \"device\": torch.device(\"cpu\")}\n",
    "\n",
    "    numbers = torch.tensor(element_numbers, dtype=torch.int64, device=dd[\"device\"]) # int64\n",
    "    pos = torch.tensor(coordinates, dtype=dd[\"dtype\"], device=dd[\"device\"]).requires_grad_(get_forces)\n",
    "\n",
    "    # Handle charge and spin\n",
    "    if batch_mode == 1:\n",
    "        if element_numbers.ndim != 2 or coordinates.ndim != 3:\n",
    "            raise ValueError(\"For batch_mode=1, element_numbers must be (batch_size, natoms) and coordinates must be (batch_size, natoms, 3).\")\n",
    "        batch_size = element_numbers.shape[0]\n",
    "        charge = torch.tensor(charge, dtype=torch.double, device=dd[\"device\"]) if isinstance(charge, (list, np.ndarray)) else torch.full((batch_size,), charge, dtype=torch.double, device=dd[\"device\"])\n",
    "        spin = torch.tensor(spin, dtype=torch.double, device=dd[\"device\"]) if isinstance(spin, (list, np.ndarray)) else torch.full((batch_size,), spin, dtype=torch.double, device=dd[\"device\"])\n",
    "    else:\n",
    "        if isinstance(charge, (list, np.ndarray)):\n",
    "            raise ValueError(\"For non-batched calculations, charge must be a single value.\")\n",
    "        if isinstance(spin, (list, np.ndarray)):\n",
    "            raise ValueError(\"For non-batched calculations, spin must be a single value.\")\n",
    "        charge = torch.tensor(charge, dtype=torch.double, device=dd[\"device\"])\n",
    "        spin = torch.tensor(spin, dtype=torch.double, device=dd[\"device\"])\n",
    "\n",
    "    # Set options\n",
    "    opts = {\"verbosity\": verbosity, \"batch_mode\": batch_mode}\n",
    "\n",
    "    calc = dxtb.Calculator(numbers, par, opts=opts, **dd)\n",
    "    calc.opts.cache = ConfigCache(enabled=True, density=True, fock=True, overlap=True, hcore=True)\n",
    "    OutputHandler.verbosity = int(verbosity)\n",
    "\n",
    "    P = calc.get_density(pos, chrg=charge, spin=spin)\n",
    "    S = calc.integrals.build_overlap(pos)\n",
    "    H = calc.integrals.build_hcore(pos)\n",
    "    F = calc.cache[\"fock\"]\n",
    "\n",
    "    res_dict = {\"F\": F, \"P\": P, \"S\": S, \"H\": H}\n",
    "\n",
    "    if get_energy:\n",
    "        res_dict[\"energy\"] = calc.get_energy(pos, chrg=charge, spin=spin)\n",
    "    if get_forces:\n",
    "        assert get_energy, \"Energy must be calculated to get forces.\"\n",
    "        assert batch_mode == 0, \"Forces are not supported in batch mode.\"\n",
    "        res_dict[\"force\"] = -torch.autograd.grad(res_dict[\"energy\"], pos)[0]\n",
    "        if get_analytical_gradients:\n",
    "            # assert batch_mode == 0, \"Forces are not supported in batch mode.\"\n",
    "            keys_to_process = [key for key in res_dict if key not in [\"energy\", \"force\"]]\n",
    "            for key in keys_to_process:\n",
    "                res_dict[f\"grad_{key}\"] = get_jacobian(res_dict[key], pos)\n",
    "\n",
    "    # Convert tensors to numpy arrays\n",
    "    for k, v in res_dict.items():\n",
    "        res_dict[k] = v.detach().cpu().numpy()\n",
    "\n",
    "    return res_dict\n",
    "\n",
    "def get_jacobian(matrix, pos):\n",
    "    matrix_jac = torch.zeros(matrix.shape + pos.shape, dtype=matrix.dtype)\n",
    "    for i, j in np.ndindex(matrix.shape):\n",
    "        matrix_jac[i, j, :, :] = torch.autograd.grad(matrix[i, j], pos, create_graph=True, retain_graph=True)[0]\n",
    "    return matrix_jac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define two methane molecules with different geometries\n",
    "element_numbers_methane1 = [6, 1, 1, 1, 1]\n",
    "coordinates_methane1 = [\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 1.089],\n",
    "    [1.026719, 0.0, -0.363],\n",
    "    [-0.51336, -0.889165, -0.363],\n",
    "    [-0.51336, 0.889165, -0.363]\n",
    "]\n",
    "\n",
    "element_numbers_methane2 = [6, 1, 1, 1, 1]\n",
    "coordinates_methane2 = [\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [0.0, 1.089, 0.0],\n",
    "    [0.0, -0.363, 1.026719],\n",
    "    [-0.889165, -0.363, -0.51336],\n",
    "    [0.889165, -0.363, -0.51336]\n",
    "]\n",
    "\n",
    "# Create batched inputs\n",
    "element_numbers_batch = np.array([\n",
    "    element_numbers_methane1, \n",
    "    element_numbers_methane2])\n",
    "\n",
    "coordinates_batch = np.array([\n",
    "    coordinates_methane1, \n",
    "    coordinates_methane2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test batch vs single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing results for molecule 1:\n",
      "  Matrix F max difference: 2.1779755776663023e-10\n",
      "  Matrix P max difference: 8.79509798323852e-11\n",
      "  Matrix S max difference: 0.0\n",
      "  Matrix H max difference: 0.0\n",
      "  Energy difference: 1.2434497875801753e-13\n",
      "\n",
      "Comparing results for molecule 2:\n",
      "  Matrix F max difference: 2.3025154005651416e-10\n",
      "  Matrix P max difference: 9.300293868363951e-11\n",
      "  Matrix S max difference: 0.0\n",
      "  Matrix H max difference: 0.0\n",
      "  Energy difference: 1.2789769243681803e-13\n"
     ]
    }
   ],
   "source": [
    "# test_batch_processing.ipynb\n",
    "\n",
    "# Compute matrices using batched processing\n",
    "res_batched = generate_xtb_matrices_fpsh_new(\n",
    "    calculator=\"dxtb\",\n",
    "    element_numbers=element_numbers_batch,\n",
    "    coordinates=coordinates_batch,\n",
    "    spin_pol=False,\n",
    "    get_energy=True,\n",
    ")\n",
    "\n",
    "# Compute matrices separately (non-batched)\n",
    "res_separate = []\n",
    "for en, coords in zip(element_numbers_batch, coordinates_batch):\n",
    "    res = generate_xtb_matrices_fpsh_new(\n",
    "        calculator=\"dxtb\",\n",
    "        element_numbers=en,\n",
    "        coordinates=coords,\n",
    "        spin_pol=False,\n",
    "        get_energy=True,\n",
    "    )\n",
    "    res_separate.append(res)\n",
    "\n",
    "# Compare the results\n",
    "for i, res_sep in enumerate(res_separate):\n",
    "    print(f\"\\nComparing results for molecule {i+1}:\")\n",
    "    for key in res_sep.keys():\n",
    "        if key == \"energy\":\n",
    "            # Compare energies\n",
    "            energy_batched = res_batched[key][i]\n",
    "            energy_separate = res_sep[key]\n",
    "            diff = abs(energy_batched - energy_separate)\n",
    "            print(f\"  Energy difference: {diff}\")\n",
    "            assert np.allclose(energy_batched, energy_separate), \"Energies do not match!\"\n",
    "        else:\n",
    "            mat_batched = res_batched[key][i]\n",
    "            mat_separate = res_sep[key]        \n",
    "            diff = np.max(np.abs(mat_batched - mat_separate))\n",
    "            print(f\"  Matrix {key} max difference: {diff}\")\n",
    "            assert np.allclose(mat_batched, mat_separate), f\"Matrix {key} does not match!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers_batch.shape: (100, 12)\n",
      "coords.shape: (100, 12, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched processing time: 2.9103 seconds\n",
      "Non-batched processing time: 8.7953 seconds\n",
      "Old tblite processing time: 5.0252 seconds\n",
      "Old dxtb processing time: 15.0312 seconds\n",
      "\n",
      "Comparing F matrix:\n",
      "  Max difference (batched vs non-batched): 5.87e-05\n",
      "  Max difference (batched vs old): 2.09e-06\n",
      "  Max difference (non-batched vs old): 5.91e-05\n",
      "\n",
      "Comparing P matrix:\n",
      "  Max difference (batched vs non-batched): 2.55e-03\n",
      "  Max difference (batched vs old): 1.06e-04\n",
      "  Max difference (non-batched vs old): 2.60e-03\n",
      "\n",
      "Comparing S matrix:\n",
      "  Max difference (batched vs non-batched): 0.00e+00\n",
      "  Max difference (batched vs old): 1.61e-10\n",
      "  Max difference (non-batched vs old): 1.61e-10\n",
      "\n",
      "Comparing H matrix:\n",
      "  Max difference (batched vs non-batched): 0.00e+00\n",
      "  Max difference (batched vs old): 2.84e-08\n",
      "  Max difference (non-batched vs old): 2.84e-08\n",
      "\n",
      "Comparing energy matrix:\n",
      "  Max difference (batched vs non-batched): 2.29e-06\n",
      "  Max difference (batched vs old): 6.26e-07\n",
      "  Max difference (non-batched vs old): 2.91e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from qcm_ml.features.xtb import generate_xtb_matrices_fpsh\n",
    "\n",
    "# Load data\n",
    "molecule = \"benzene\"\n",
    "file = f\"../../../data/rmd17/npz_data/rmd17_{molecule}.npz\"\n",
    "data = np.load(file)\n",
    "\n",
    "numbers = data[\"nuclear_charges\"]\n",
    "coords = data[\"coords\"]\n",
    "\n",
    "# Repeat nuclear charges to match batch size\n",
    "numbers_batch = np.tile(numbers, (len(coords), 1))\n",
    "\n",
    "# Limit the number of molecules for testing\n",
    "max_nb_mols = 1000\n",
    "numbers_batch = numbers_batch[:max_nb_mols]\n",
    "coords = coords[:max_nb_mols]\n",
    "print(f\"numbers_batch.shape: {numbers_batch.shape}\") \n",
    "print(f\"coords.shape: {coords.shape}\")\n",
    "\n",
    "# Batched version\n",
    "start_batched = time.time()\n",
    "res_batched = generate_xtb_matrices_fpsh_new(\n",
    "    calculator=\"dxtb\",\n",
    "    element_numbers=numbers_batch,\n",
    "    coordinates=coords,\n",
    "    spin_pol=False,\n",
    "    get_energy=True,\n",
    ")\n",
    "end_batched = time.time()\n",
    "print(f\"Batched processing time: {end_batched - start_batched:.4f} seconds\")\n",
    "\n",
    "# Non-batched version\n",
    "start_non_batched = time.time()\n",
    "res_non_batched = []\n",
    "for i in range(max_nb_mols):\n",
    "    res = generate_xtb_matrices_fpsh_new(\n",
    "        calculator=\"dxtb\",\n",
    "        element_numbers=numbers_batch[i],\n",
    "        coordinates=coords[i],\n",
    "        spin_pol=False,\n",
    "        get_energy=True,\n",
    "        get_forces=False\n",
    "    )\n",
    "    res_non_batched.append(res)\n",
    "end_non_batched = time.time()\n",
    "print(f\"Non-batched processing time: {end_non_batched - start_non_batched:.4f} seconds\")\n",
    "\n",
    "# Old tblite version\n",
    "start_old = time.time()\n",
    "res_old = []\n",
    "for i in range(max_nb_mols):\n",
    "    res = generate_xtb_matrices_fpsh(\n",
    "        calculator=\"tblite\",\n",
    "        element_numbers=numbers_batch[i],\n",
    "        coordinates=coords[i],\n",
    "        spin_pol=False,\n",
    "        get_energy=True,\n",
    "        get_forces=False\n",
    "    )\n",
    "    res_old.append(res)\n",
    "\n",
    "end_old = time.time()\n",
    "print(f\"Old tblite processing time: {end_old - start_old:.4f} seconds\")\n",
    "\n",
    "# Old dxtb version\n",
    "start_old_dxtb = time.time()\n",
    "res_old_dxtb = []\n",
    "for i in range(max_nb_mols):\n",
    "    res = generate_xtb_matrices_fpsh(\n",
    "        calculator=\"dxtb\",\n",
    "        element_numbers=numbers_batch[i],\n",
    "        coordinates=coords[i],\n",
    "        spin_pol=False,\n",
    "        get_energy=True,\n",
    "        get_forces=False\n",
    "    )\n",
    "    res_old_dxtb.append(res)\n",
    "end_old_dxtb = time.time()\n",
    "print(f\"Old dxtb processing time: {end_old_dxtb - start_old_dxtb:.4f} seconds\")\n",
    "\n",
    "# Function to compute maximum difference\n",
    "def max_diff(matrix1, matrix2):\n",
    "    return np.max(np.abs(matrix1 - matrix2))\n",
    "\n",
    "# Compare FPSH matrices (Fock, Density, Overlap, Hamiltonian) and energy\n",
    "def compare_results(batched, non_batched, old, keys):\n",
    "    for key in keys:\n",
    "        if key == \"energy\":\n",
    "            batched_val = batched[key]\n",
    "            non_batched_val = np.array([res[key] for res in non_batched])\n",
    "            old_val = np.array([res[key] for res in old])\n",
    "        else:\n",
    "            batched_val = batched[key]\n",
    "            non_batched_val = np.array([res[key] for res in non_batched])\n",
    "            old_val = np.array([res[key] for res in old])\n",
    "\n",
    "        # Compare the three versions\n",
    "        print(f\"\\nComparing {key} matrix:\")\n",
    "        print(f\"  Max difference (batched vs non-batched): {max_diff(batched_val, non_batched_val):.2e}\")\n",
    "        print(f\"  Max difference (batched vs old): {max_diff(batched_val, old_val):.2e}\")\n",
    "        print(f\"  Max difference (non-batched vs old): {max_diff(non_batched_val, old_val):.2e}\")\n",
    "\n",
    "# List of keys to compare\n",
    "keys_to_compare = [\"F\", \"P\", \"S\", \"H\", \"energy\"]\n",
    "\n",
    "# Run comparison\n",
    "compare_results(res_batched, res_non_batched, res_old, keys_to_compare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orbnet_tblite_libpath",
   "language": "python",
   "name": "orbnet_tblite_libpath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
