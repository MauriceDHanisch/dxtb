{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b4dda4",
   "metadata": {},
   "source": [
    "# You can run the cell below multiple times and see that randomly 1 out of 2 errors appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d30034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dxtb\n",
    "\n",
    "problematic_batch_path = \"problematic_batch_for_full.pt\"\n",
    "\n",
    "dd = {\"dtype\": torch.float64, \"device\": torch.device(\"cuda:0\")}\n",
    "opts = {\"scf_mode\": \"full\", \"batch_mode\": 1, \"int_driver\": \"libcint\"}\n",
    "\n",
    "# Load the problematic batch\n",
    "problematic_batch = torch.load(problematic_batch_path, weights_only=False)\n",
    "numbers = problematic_batch[\"numbers\"].to(dd[\"device\"])\n",
    "positions = problematic_batch[\"positions\"].to(**dd)\n",
    "\n",
    "batch_size = numbers.shape[0]\n",
    "charges = torch.full((batch_size,), 0, **dd)\n",
    "\n",
    "calc = dxtb.Calculator(numbers, dxtb.GFN1_XTB, **dd, opts=opts)\n",
    "\n",
    "e = calc.get_energy(positions, chrg=charges)\n",
    "forces = torch.autograd.grad(sum(e), positions, retain_graph=True)[0]\n",
    "\n",
    "# Features calc\n",
    "func = lambda e, p: -torch.autograd.grad(e.sum(), p, retain_graph=True)[0]\n",
    "res = func(e, positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d36db4",
   "metadata": {},
   "source": [
    "# Or just run this looped version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2743f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:23<00:00,  4.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import dxtb\n",
    "from tqdm import tqdm\n",
    "\n",
    "dd = {\"dtype\": torch.float32, \"device\": torch.device(\"cuda:0\")}\n",
    "opts = {\"scf_mode\": \"full\", \"batch_mode\": 1, \"int_driver\": \"libcint\"}\n",
    "\n",
    "# Load the problematic batch\n",
    "problematic_batch = torch.load(problematic_batch_path, weights_only=False)\n",
    "numbers = problematic_batch[\"numbers\"].to(dd[\"device\"])\n",
    "positions = problematic_batch[\"positions\"].to(**dd)\n",
    "\n",
    "batch_size = numbers.shape[0]\n",
    "charges = torch.full((batch_size,), 0, **dd)\n",
    "\n",
    "calc = dxtb.Calculator(numbers, dxtb.GFN1_XTB, **dd, opts=opts)\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    e = calc.get_energy(positions, chrg=charges)\n",
    "    forces = torch.autograd.grad(sum(e), positions, retain_graph=True)[0]\n",
    "\n",
    "    # Features calc\n",
    "    func = lambda e, p: -torch.autograd.grad(e.sum(), p, retain_graph=True)[0]\n",
    "    res = func(e, positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7674a8",
   "metadata": {},
   "source": [
    "# Checks about the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c49088",
   "metadata": {},
   "source": [
    "It is a sample from the Transition1x dataset. Specifically C2H2N2O/rxn2091. So a single molecule at different steps in the reaction path. Units of the positions are Bohr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8933865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers.shape: torch.Size([64, 7])\n",
      "positions.shape: torch.Size([64, 7, 3])\n",
      "\n",
      "Subset:\n",
      "numbers[0]: tensor([8, 6, 7, 6, 7, 1, 1], device='cuda:0', dtype=torch.int32)\n",
      "positions[0]: tensor([[ 0.8494,  3.3460,  0.0348],\n",
      "        [ 1.2790, -1.3759, -0.2903],\n",
      "        [-0.2177, -1.3857, -2.1151],\n",
      "        [-1.1522, -0.2871,  0.3423],\n",
      "        [-1.1985,  2.4734,  0.5247],\n",
      "        [ 3.2372, -1.7409,  0.1731],\n",
      "        [-2.7249, -1.2143,  1.2866]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "Properties of the problematic batch:\n",
      "isnan positions: False\n",
      "isinf positions: False\n",
      "max positions: 3.877077102661133\n",
      "min positions: -3.9229071140289307\n"
     ]
    }
   ],
   "source": [
    "problematic_batch = torch.load(problematic_batch_path, weights_only=False)\n",
    "numbers = problematic_batch[\"numbers\"]\n",
    "positions = problematic_batch[\"positions\"]\n",
    "\n",
    "print(f\"numbers.shape: {numbers.shape}\")\n",
    "print(f\"positions.shape: {positions.shape}\")\n",
    "\n",
    "print(f\"\\nSubset:\")\n",
    "idx = 0\n",
    "print(f\"numbers[0]: {numbers[idx]}\")\n",
    "print(f\"positions[0]: {positions[idx]}\")\n",
    "\n",
    "print(\"\\nProperties of the problematic batch:\")\n",
    "print(f\"isnan positions: {torch.isnan(positions).any()}\")\n",
    "print(f\"isinf positions: {torch.isinf(positions).any()}\")\n",
    "print(f\"max positions: {positions.max()}\")\n",
    "print(f\"min positions: {positions.min()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ceef5",
   "metadata": {},
   "source": [
    "# Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f27ac10",
   "metadata": {},
   "source": [
    "- Env:\n",
    "    - Python 3.11\n",
    "    - Just pip install -e . of the main branch of dxtb\n",
    "    - pip install jupyter notebook tqdm torch tad-libcint\n",
    "\n",
    "    - Torch 2.5.1, CUDA 12.4, driver 550.120\n",
    "\n",
    "\n",
    "- If restarting the kernel after each run it does not break. Maybe something is cached in the calculator? \n",
    "\n",
    "- It is only breaking when using a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23cd5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dxtb_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
