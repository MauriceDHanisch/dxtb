{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ed616db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of carbon atoms in alkane_9_carbons: 2\n",
      "Nb of atoms: 8\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import h5py\n",
    "N_Cs = 2\n",
    "\n",
    "with h5py.File('../dxtb/dxtb-gpu/gpu-cpu_analysis/rdkit/alkanes_data_500.hdf5', 'r') as f:\n",
    "    for mol_name, data in f.items():\n",
    "        if mol_name == f\"alkane_{N_Cs}_carbons\":\n",
    "            atomic_numbers = data['atomic_numbers'][:]\n",
    "            coordinates = data['coordinates'][:]\n",
    "\n",
    "print(f\"Number of carbon atoms in {mol_name}: {N_Cs}\")\n",
    "print(f\"Nb of atoms: {len(atomic_numbers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20907998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of carbon atoms in alkane_9_carbons: 2\n",
      "Nb of atoms: 8\n",
      "batch_size: 64\n"
     ]
    }
   ],
   "source": [
    "import dxtb\n",
    "from dxtb._src.typing import DD\n",
    "import torch\n",
    "from dxtb.config import ConfigCache\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "print(f\"Number of carbon atoms in {mol_name}: {N_Cs}\")\n",
    "print(f\"Nb of atoms: {len(atomic_numbers)}\")\n",
    "print(f\"batch_size: {batch_size}\")\n",
    "\n",
    "dd = {\"device\": torch.device(\"cuda:0\"), \"dtype\": torch.float64}\n",
    "numbers = torch.tensor(atomic_numbers, device=dd[\"device\"], dtype=torch.int32)\n",
    "positions = torch.tensor(coordinates, **dd).requires_grad_()\n",
    "charges = torch.tensor(0.0, **dd)\n",
    "# numbers = torch.stack([numbers] * batch_size)\n",
    "# positions = torch.stack([positions] * batch_size).requires_grad_()\n",
    "# charges = torch.zeros((batch_size,), device=dd[\"device\"], dtype=dd[\"dtype\"])\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caf565a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Energy: -2.02464984361025 Hartree.\n",
      "\n",
      "\n",
      "Timings\n",
      "-------\n",
      "\n",
      "\u001b[1mObjective                Time (s)        % Total\u001b[0m\n",
      "------------------------------------------------\n",
      "\u001b[1mClassicals                  0.006          10.74\u001b[0m\n",
      " - DispersionD3        \u001b[37m     0.005          83.78\u001b[0m\n",
      " - Repulsion           \u001b[37m     0.001          12.11\u001b[0m\n",
      " - Halogen             \u001b[37m     0.000           2.58\u001b[0m\n",
      "\u001b[1mIntegrals                   0.003           5.48\u001b[0m\n",
      " - Overlap             \u001b[37m     0.002          47.75\u001b[0m\n",
      " - Core Hamiltonian    \u001b[37m     0.002          51.37\u001b[0m\n",
      "\u001b[1mSCF                         0.031          51.23\u001b[0m\n",
      " - Interaction Cache   \u001b[37m     0.001           2.59\u001b[0m\n",
      " - Potential           \u001b[37m     0.006          17.81\u001b[0m\n",
      " - Fock build          \u001b[37m     0.000           1.24\u001b[0m\n",
      " - Diagonalize         \u001b[37m     0.009          29.06\u001b[0m\n",
      " - Density             \u001b[37m     0.001           4.64\u001b[0m\n",
      " - Charges             \u001b[37m     0.002           5.37\u001b[0m\n",
      "\u001b[1mForces autograd             0.018          29.62\u001b[0m\n",
      "------------------------------------------------\n",
      "Sum                    \u001b[37m     0.059          97.08\u001b[0m\n",
      "\u001b[1mTotal                       0.060         100.00\u001b[0m\n",
      "Total Energy: -2.02464984361025 Hartree.\n",
      "Total Energy: -2.02464984361025 Hartree.\n"
     ]
    }
   ],
   "source": [
    "opts = {\"scf_mode\": \"full\", \"batch_mode\": 0, \"int_driver\": \"libcint\", \"maxiter\":10000}\n",
    "\n",
    "calc = dxtb.Calculator(numbers, dxtb.GFN1_XTB, **dd, opts=opts, timer=True)\n",
    "calc.opts.cache = ConfigCache(enabled=False, density=True, fock=True, overlap=False)\n",
    "dxtb.timer.reset()\n",
    "e = calc.get_energy(positions, chrg=charges)\n",
    "dxtb.timer.start(\"Forces autograd\")\n",
    "forces = torch.autograd.grad(e, positions, retain_graph=True)[0]\n",
    "dxtb.timer.stop(\"Forces autograd\")\n",
    "dxtb.timer.print(v=0)\n",
    "\n",
    "results[f\"e_{opts['scf_mode']}\"] = e\n",
    "results[f\"forces_{opts['scf_mode']}\"] = forces\n",
    "results[f\"Fgrad_{opts['scf_mode']}\"] = torch.autograd.grad(calc.cache[\"fock\"].sum(), positions, retain_graph=True)[0]\n",
    "results[f\"Pgrad_{opts['scf_mode']}\"] = torch.autograd.grad(calc.get_density(positions, chrg=charges).sum(), positions, retain_graph=True)[0]\n",
    "\n",
    "# For reconnect modes\n",
    "scf_charges = calc.get_charges(positions, chrg=charges)\n",
    "scf_charge_mode = opts[\"scf_mode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a880f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = {\"scf_mode\": \"implicit\", \"batch_mode\":0, \"int_driver\": \"libcint\", \"maxiter\":10000}\n",
    "\n",
    "calc = dxtb.Calculator(numbers, dxtb.GFN1_XTB, **dd, opts=opts, timer=True)\n",
    "calc.opts.cache = ConfigCache(enabled=False, density=True, fock=True, overlap=False)\n",
    "dxtb.timer.reset()\n",
    "e = calc.get_energy(positions, chrg=charges)\n",
    "dxtb.timer.start(\"Forces autograd\")\n",
    "forces = torch.autograd.grad(e, positions, retain_graph=True)[0]\n",
    "dxtb.timer.stop(\"Forces autograd\")\n",
    "dxtb.timer.print(v=0)\n",
    "\n",
    "results[f\"e_{opts['scf_mode']}\"] = e\n",
    "results[f\"forces_{opts['scf_mode']}\"] = forces\n",
    "results[f\"Fgrad_{opts['scf_mode']}\"] = torch.autograd.grad(calc.cache[\"fock\"].sum(), positions, retain_graph=True)[0]\n",
    "results[f\"Pgrad_{opts['scf_mode']}\"] = torch.autograd.grad(calc.get_density(positions, chrg=charges).sum(), positions, retain_graph=True)[0]\n",
    "\n",
    "# For reconnect modes\n",
    "scf_charges = calc.get_charges(positions, chrg=charges)\n",
    "scf_charge_mode = opts[\"scf_mode\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a7a5b6",
   "metadata": {},
   "source": [
    "# Gradchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "185d15f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy\n",
      "Gradcheck passed: True\n",
      "Fock\n"
     ]
    },
    {
     "ename": "GradcheckError",
     "evalue": "Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor([[ 9.1775e-04,  0.0000e+00,  0.0000e+00,  ..., -7.7745e-04,\n         -7.9411e-12, -9.3888e-03],\n        [-2.4456e-02,  0.0000e+00,  0.0000e+00,  ...,  1.8232e-03,\n          8.7683e-12,  1.0153e-02],\n        [-1.4742e-02,  0.0000e+00,  0.0000e+00,  ...,  9.0220e-04,\n          1.4517e-11,  1.7044e-02],\n        ...,\n        [ 5.4271e-03,  0.0000e+00,  0.0000e+00,  ...,  2.7158e-03,\n          7.6143e-12,  1.0155e-02],\n        [ 5.5978e-03,  0.0000e+00,  0.0000e+00,  ...,  4.3776e-03,\n          7.2094e-12,  9.3194e-03],\n        [-3.4624e-03,  0.0000e+00,  0.0000e+00,  ..., -6.0885e-03,\n         -5.2169e-12, -7.1223e-03]], device='cuda:0', dtype=torch.float64)\nanalytical:tensor([[-3.1492e-05,  0.0000e+00,  0.0000e+00,  ..., -1.1486e-05,\n         -1.3174e-13, -2.0574e-04],\n        [ 8.3921e-04,  0.0000e+00,  0.0000e+00,  ..., -1.2915e-04,\n         -1.0590e-12, -1.4031e-03],\n        [ 5.0586e-04,  0.0000e+00,  0.0000e+00,  ..., -8.2383e-05,\n         -4.3039e-13, -5.3240e-04],\n        ...,\n        [-6.5960e-04,  0.0000e+00,  0.0000e+00,  ..., -9.9603e-05,\n         -9.6576e-13,  6.5560e-05],\n        [-8.0370e-04,  0.0000e+00,  0.0000e+00,  ..., -6.1590e-05,\n         -3.8167e-13,  3.9301e-04],\n        [ 3.5208e-04,  0.0000e+00,  0.0000e+00,  ...,  1.3004e-04,\n          9.5855e-13,  1.3950e-04]], device='cuda:0', dtype=torch.float64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGradcheckError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m calc.cache[\u001b[33m\"\u001b[39m\u001b[33mfock\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFock\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mrun_gradcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfock_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Density (matrix output)\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdensity_fn\u001b[39m(pos):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mrun_gradcheck\u001b[39m\u001b[34m(fn, inputs)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_gradcheck\u001b[39m(fn, inputs):\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# gradcheck assumes float64 and requires_grad=True\u001b[39;00m\n\u001b[32m     15\u001b[39m     inputs = \u001b[38;5;28mtuple\u001b[39m(i.detach().double().requires_grad_() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     passed = \u001b[43mgradcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGradcheck passed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dxtb/lib/python3.11/site-packages/torch/autograd/gradcheck.py:2052\u001b[39m, in \u001b[36mgradcheck\u001b[39m\u001b[34m(func, inputs, eps, atol, rtol, raise_exception, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[39m\n\u001b[32m   2050\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2051\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2052\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gradcheck_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dxtb/lib/python3.11/site-packages/torch/autograd/gradcheck.py:2081\u001b[39m, in \u001b[36m_gradcheck_helper\u001b[39m\u001b[34m(func, inputs, eps, atol, rtol, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[39m\n\u001b[32m   2076\u001b[39m _check_outputs(outputs)\n\u001b[32m   2078\u001b[39m gradcheck_fn = functools.partial(\n\u001b[32m   2079\u001b[39m     _fast_gradcheck \u001b[38;5;28;01mif\u001b[39;00m fast_mode \u001b[38;5;28;01melse\u001b[39;00m _slow_gradcheck, masked=masked\n\u001b[32m   2080\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2081\u001b[39m \u001b[43m_gradcheck_real_imag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradcheck_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2084\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2086\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2087\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2088\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2089\u001b[39m \u001b[43m    \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2090\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_grad_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2091\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_forward_ad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_forward_ad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2092\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_backward_ad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_backward_ad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2093\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2094\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_undefined_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_undefined_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2095\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2097\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_batched_forward_grad:\n\u001b[32m   2098\u001b[39m     _test_batched_grad_forward_ad(func, tupled_inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dxtb/lib/python3.11/site-packages/torch/autograd/gradcheck.py:1491\u001b[39m, in \u001b[36m_gradcheck_real_imag\u001b[39m\u001b[34m(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, check_forward_ad, check_backward_ad, nondet_tol, check_undefined_grad)\u001b[39m\n\u001b[32m   1478\u001b[39m         gradcheck_fn(\n\u001b[32m   1479\u001b[39m             real_fn,\n\u001b[32m   1480\u001b[39m             real_func_out,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1488\u001b[39m             complex_indices=complex_out_indices,\n\u001b[32m   1489\u001b[39m         )\n\u001b[32m   1490\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m         \u001b[43mgradcheck_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1495\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m            \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1499\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheck_grad_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1500\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_forward_ad:\n\u001b[32m   1504\u001b[39m     complex_inp_indices = [\n\u001b[32m   1505\u001b[39m         i\n\u001b[32m   1506\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, inp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tupled_inputs)\n\u001b[32m   1507\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(inp) \u001b[38;5;129;01mand\u001b[39;00m inp.is_complex()\n\u001b[32m   1508\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dxtb/lib/python3.11/site-packages/torch/autograd/gradcheck.py:1632\u001b[39m, in \u001b[36m_slow_gradcheck\u001b[39m\u001b[34m(func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, nondet_tol, use_forward_ad, complex_indices, test_imag, masked)\u001b[39m\n\u001b[32m   1630\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m j, (a, n) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(analytical, numerical[i])):\n\u001b[32m   1631\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _allclose_with_type_promotion(a, n.to(a.device), rtol, atol):\n\u001b[32m-> \u001b[39m\u001b[32m1632\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m GradcheckError(\n\u001b[32m   1633\u001b[39m                     _get_notallclose_msg(a, n, i, j, complex_indices, test_imag)\n\u001b[32m   1634\u001b[39m                 )\n\u001b[32m   1636\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mGradcheckError\u001b[39m: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor([[ 9.1775e-04,  0.0000e+00,  0.0000e+00,  ..., -7.7745e-04,\n         -7.9411e-12, -9.3888e-03],\n        [-2.4456e-02,  0.0000e+00,  0.0000e+00,  ...,  1.8232e-03,\n          8.7683e-12,  1.0153e-02],\n        [-1.4742e-02,  0.0000e+00,  0.0000e+00,  ...,  9.0220e-04,\n          1.4517e-11,  1.7044e-02],\n        ...,\n        [ 5.4271e-03,  0.0000e+00,  0.0000e+00,  ...,  2.7158e-03,\n          7.6143e-12,  1.0155e-02],\n        [ 5.5978e-03,  0.0000e+00,  0.0000e+00,  ...,  4.3776e-03,\n          7.2094e-12,  9.3194e-03],\n        [-3.4624e-03,  0.0000e+00,  0.0000e+00,  ..., -6.0885e-03,\n         -5.2169e-12, -7.1223e-03]], device='cuda:0', dtype=torch.float64)\nanalytical:tensor([[-3.1492e-05,  0.0000e+00,  0.0000e+00,  ..., -1.1486e-05,\n         -1.3174e-13, -2.0574e-04],\n        [ 8.3921e-04,  0.0000e+00,  0.0000e+00,  ..., -1.2915e-04,\n         -1.0590e-12, -1.4031e-03],\n        [ 5.0586e-04,  0.0000e+00,  0.0000e+00,  ..., -8.2383e-05,\n         -4.3039e-13, -5.3240e-04],\n        ...,\n        [-6.5960e-04,  0.0000e+00,  0.0000e+00,  ..., -9.9603e-05,\n         -9.6576e-13,  6.5560e-05],\n        [-8.0370e-04,  0.0000e+00,  0.0000e+00,  ..., -6.1590e-05,\n         -3.8167e-13,  3.9301e-04],\n        [ 3.5208e-04,  0.0000e+00,  0.0000e+00,  ...,  1.3004e-04,\n          9.5855e-13,  1.3950e-04]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import gradcheck\n",
    "from dxtb import OutputHandler\n",
    "from dxtb.config import ConfigCache\n",
    "\n",
    "OutputHandler.verbosity = 0\n",
    "\n",
    "# Inputs (must be float64)\n",
    "positions_d = positions.detach().double().requires_grad_()\n",
    "charges_d = charges.double()\n",
    "\n",
    "calc.opts.cache = ConfigCache(enabled=False, fock=True, density=True)\n",
    "\n",
    "def run_gradcheck(fn, inputs):\n",
    "    # gradcheck assumes float64 and requires_grad=True\n",
    "    inputs = tuple(i.detach().double().requires_grad_() for i in inputs)\n",
    "    passed = gradcheck(fn, inputs, eps=1e-6, atol=1e-3, rtol=1e-3, nondet_tol=1e-5)\n",
    "    print(f\"Gradcheck passed: {passed}\")\n",
    "\n",
    "# Energy (scalar output)\n",
    "def energy_fn(pos):\n",
    "    return calc.get_energy(pos, chrg=charges_d)\n",
    "\n",
    "print(\"Energy\")\n",
    "run_gradcheck(energy_fn, (positions_d,))\n",
    "\n",
    "# Fock (matrix output)\n",
    "def fock_fn(pos):\n",
    "    _ = calc.get_energy(pos, chrg=charges_d)  # populate cache\n",
    "    return calc.cache[\"fock\"]\n",
    "\n",
    "print(\"Fock\")\n",
    "run_gradcheck(fock_fn, (positions_d,))\n",
    "\n",
    "# Density (matrix output)\n",
    "def density_fn(pos):\n",
    "    return calc.get_density(pos, chrg=charges_d)\n",
    "\n",
    "print(\"Density\")\n",
    "run_gradcheck(density_fn, (positions_d,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a25de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import gradcheck\n",
    "from dxtb import OutputHandler\n",
    "\n",
    "OutputHandler.verbosity = 0\n",
    "\n",
    "def run_gradcheck(fn, inputs):\n",
    "    inputs = tuple(i.detach().requires_grad_() for i in inputs)\n",
    "    passed = gradcheck(fn, inputs)\n",
    "    print(f\"Gradcheck passed: {passed}\")\n",
    "\n",
    "# Functions must return tuple of tensor outputs in float64\n",
    "def energy_fn(pos):\n",
    "    return (calc.get_energy(pos, chrg=charges),)\n",
    "\n",
    "def fock_fn(pos):\n",
    "    calc.get_energy(pos, chrg=charges)  # populate cache\n",
    "    return (calc.cache[\"fock\"].sum(),)\n",
    "\n",
    "def density_fn(pos):\n",
    "    return (calc.get_density(pos, chrg=charges).sum(),)\n",
    "\n",
    "# Inputs\n",
    "positions_d = positions.detach().requires_grad_()\n",
    "charges_d = charges\n",
    "\n",
    "print(\"Energy\")\n",
    "run_gradcheck(energy_fn, (positions_d,))\n",
    "\n",
    "print(\"Fock\")\n",
    "run_gradcheck(fock_fn, (positions_d,))\n",
    "\n",
    "print(\"Density\")\n",
    "run_gradcheck(density_fn, (positions_d,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd07ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import gradcheck\n",
    "from torch.autograd.gradcheck import _get_numerical_jacobian, _as_tuple\n",
    "from dxtb import OutputHandler\n",
    "\n",
    "OutputHandler.verbosity = 0\n",
    "\n",
    "def compare_grads(fn, inputs):\n",
    "    # Prepare input\n",
    "    inputs = tuple(i.detach().requires_grad_() for i in _as_tuple(inputs))\n",
    "    output = fn(*inputs)\n",
    "    output = _as_tuple(output)\n",
    "\n",
    "    # Compute autograd\n",
    "    autograd_grads = torch.autograd.grad(output, inputs, grad_outputs=[torch.ones_like(o) for o in output], retain_graph=True)\n",
    "\n",
    "    # Compute numerical\n",
    "    numerical_grads = _get_numerical_jacobian(fn, inputs, eps=1e-6)\n",
    "\n",
    "    # Print comparison\n",
    "    for i, (a, n) in enumerate(zip(autograd_grads, numerical_grads)):\n",
    "        n_tensor = n[0][0]  # FIXED: Unwrap twice\n",
    "        print(f\"[Input {i}] max(abs diff): {(a - n_tensor).abs().max().item():.2e}\")\n",
    "        # print(f\"Autograd:\\n{a}\\nNumerical:\\n{n_tensor}\")\n",
    "\n",
    "def energy_fn(pos):\n",
    "    return calc.get_energy(pos, chrg=charges)\n",
    "print(\"Energy\")\n",
    "compare_grads(energy_fn, (positions,))\n",
    "\n",
    "def fock_fn(pos):\n",
    "    calc.get_energy(pos, chrg=charges)\n",
    "    return calc.cache[\"fock\"].sum()\n",
    "print(\"Fock\")\n",
    "compare_grads(fock_fn, (positions,))\n",
    "\n",
    "def density_fn(pos):\n",
    "    return calc.get_density(pos, chrg=charges).sum()\n",
    "print(\"Density\")\n",
    "compare_grads(density_fn, (positions,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6cb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dxtb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
